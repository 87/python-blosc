====================================================
 Announcing python-blosc 1.0.1
 A Python wrapper for the Blosc compression library
====================================================

What is it?
===========

Blosc (http://blosc.pytables.org) is a high performance compressor
optimized for binary data.  It has been designed to transmit data to
the processor cache faster than the traditional, non-compressed,
direct memory fetch approach via a memcpy() OS call.

Blosc works well for compressing numerical arrays that contains data
with relatively low entropy, like sparse data, time series, grids with
regular-spaced values, etc.

This is a Python package that wraps it.

What is new?
============

Everything.  This is the first public version of the Python wrapper
for Blosc (1.1.1).  It supports Python 2.6, 2.7 and 3.1.

The API is very simple and it loosely follows that of the zlib module.
There are two basic functions, `compress()` and `decompress()`, as
well as two additional calls specific for compressing NumPy arrays,
namely `pack_array()` and `unpack_array`.  There are also utilities
for changing dynamically the number of threads used or to release
resources when you are not going to need blosc for a while.

Usage
=====

Some basic examples:

# Let's create a NumPy array with 80 MB full of data
>>> import numpy as np
>>> a = np.linspace(0, 100, 1e7)
>>> bytes_array = a.tostring()  # get a bytes stream

# Blosc as a very fast compressor
>>> import zlib
>>> %time zpacked = zlib.compress(bytes_array)
CPU times: user 7.66 s, sys: 0.04 s, total: 7.70 s
Wall time: 7.72 s
>>> import blosc
>>> %time bpacked = blosc.compress(bytes_array, typesize=8)
CPU times: user 0.20 s, sys: 0.03 s, total: 0.23 s
Wall time: 0.02 s  # ~ 400x faster than zlib (using 16 threads here)

# ... that is optimized for compressing binary data ...
>>> len(zpacked)
52994692
>>>  len(bytes_array) / float(len(zpacked))
1.5095851486409242   # zlib achieves a 1.5x compression ratio
>>> len(bpacked)
8040187
>>>  len(bytes_array) / float(len(bpacked))
9.9500173316864391   # blosc reaches almost a 10x compression ratio

# Blosc is also extremely fast when decompressing
>>> %time bytes_array2 = zlib.decompress(zpacked)
CPU times: user 0.62 s, sys: 0.02 s, total: 0.64 s
Wall time: 0.64 s
>>> %time bytes_array2 = blosc.decompress(bpacked)
CPU times: user 0.15 s, sys: 0.06 s, total: 0.20 s
Wall time: 0.02 s   # ~ 30x times faster than zlib

# You can pack and unpack NumPy arrays very easily too:
>>> packed = blosc.pack_array(a)
>>> a2 = blosc.unpack_array(packed)
>>> np.alltrue(a == a2)
True

[using a machine with 8 physical cores and the IPython shell for the
%time magic command]

Download sources
================

Go to:

http://github.com/FrancescAlted/python-blosc

and download the most recent release from here.

Blosc is distributed using the MIT license, see LICENSES/BLOSC.txt for
details.

Mailing list
============

There is an official mailing list for Blosc at:

blosc@googlegroups.com
http://groups.google.es/group/blosc


----

  **Enjoy data!**
